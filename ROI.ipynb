{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSas_oTnuvIu"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "\n",
        "# Input and output video file paths\n",
        "input_video_path = 'Input vedio file path'\n",
        "output_video_path = 'output vedio file path'\n",
        "\n",
        "# Define the landmark numbers corresponding to the given coordinates\n",
        "landmark_numbers = [\n",
        "    [103, 104, 105, 66, 107, 9, 336, 296, 334, 333, 332, 297, 338, 10, 109, 67],  # Coordinates for the first polygon\n",
        "    [198, 233, 111, 187],  # Coordinates for the second polygon\n",
        "    [412, 371, 411, 340]   # Coordinates for the third polygon\n",
        "]\n",
        "\n",
        "# Open input video file\n",
        "cap = cv2.VideoCapture(input_video_path)\n",
        "if not cap.isOpened():\n",
        "    print(\"Error: Could not open video.\")\n",
        "    exit()\n",
        "\n",
        "# This is for Vedio Properties\n",
        "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "# codec for creating vedio with ROI\n",
        "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "# Initialize MediaPipe Face Mesh\n",
        "with mp_face_mesh.FaceMesh(\n",
        "        max_num_faces=1,\n",
        "        refine_landmarks=True,\n",
        "        min_detection_confidence=0.5,\n",
        "        min_tracking_confidence=0.5) as face_mesh:\n",
        "    while cap.isOpened():\n",
        "        # Read frame from the video\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # This is to Convert the frame from BGR to RGB\n",
        "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Processing the frame with MediaPipe Face Mesh\n",
        "        results = face_mesh.process(frame_rgb)\n",
        "\n",
        "        # Drawing the face mesh landmarks on the frame that is generated\n",
        "        if results.multi_face_landmarks:\n",
        "            for face_landmarks in results.multi_face_landmarks:\n",
        "                # Extracting landmark coordinates for each polygon\n",
        "                for polygon_landmarks in landmark_numbers:\n",
        "                    polygon_coords = [(int(face_landmarks.landmark[landmark_number].x * frame_width),\n",
        "                                       int(face_landmarks.landmark[landmark_number].y * frame_height))\n",
        "                                      for landmark_number in polygon_landmarks]\n",
        "                    pts = np.array(polygon_coords, np.int32)\n",
        "                    pts = pts.reshape((-1, 1, 2))\n",
        "                    cv2.polylines(frame, [pts], isClosed=True, color=(255, 0, 0), thickness=2)\n",
        "\n",
        "        # Write the processed frame to the output video\n",
        "        out.write(frame)\n",
        "\n",
        "# Release resources\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    }
  ]
}